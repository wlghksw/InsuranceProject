**ì¢…ì‹  ë³´í—˜ ë§ì¶¤ ì¶”ì²œ**

ê°„ë‹¨í•œ KNN ê¸°ë°˜ì˜ ì¢…ì‹ ë³´í—˜ì„ ì¶”ì²œ
CSVì˜ ìŠ¤í‚¤ë§ˆì— ë§ì¶° ë¼ë²¨ ì¸ì½”ë”©/ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•˜ê³ , 
ì‚¬ìš©ìì˜ ì…ë ¥(ì„±ë³„, í¬ë§ ë³´í—˜ë£Œ, ì§€ê¸‰ê¸ˆì•¡, ë‚˜ì´, ì§ì—…)ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ê¹Œìš´ ìƒí’ˆ Topâ€‘Kë¥¼ ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥

**ì¶”ì²œ ë¡œì§**

ì„±ë³„ ë¶„ë¦¬ ìŠ¤ì¼€ì¼ë§: ë‚¨/ë…€ í’€ì„ ë¶„ë¦¬í•˜ì—¬ ê°ê° StandardScalerë¡œ ì •ê·œí™” í›„ KNN ê±°ë¦¬ ê¸°ë°˜ ê·¼ì ‘ë„ ê³„ì‚°

ì§ì—… ìœ„í—˜ë„ ì¶”ì •: ì§ì—…ëª…â†’ìœ„í—˜ë„ ë§¤í•‘ì´ ì• ë§¤í•  ê²½ìš°, ë™ì¼ ì§ì—…ì˜ ìœ„í—˜ë„ë¥¼ ì‚¬ìš©

ì •ë ¬ ì˜µì…˜: distance(ê¸°ë³¸), premium(ë³´í—˜ë£Œ ì°¨ ì ˆëŒ“ê°’), coverage(ì§€ê¸‰ê¸ˆì•¡ ì°¨ ì ˆëŒ“ê°’)

ìƒí’ˆëª… ë³µì›: ë‚´ë¶€ì ìœ¼ë¡œ ë¼ë²¨ ì¸ì½”ë”©í•˜ë˜ ê²°ê³¼ ì¶œë ¥ ì‹œ ì›ë˜ ìƒí’ˆëª…ìœ¼ë¡œ ë³µì›


## Repository êµ¬ì¡°

```
life-insurance-recommender/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â”œâ”€ data/
â”‚  â””â”€ README.md
â”œâ”€ src/
â”‚  â””â”€ life_insurance_recommender/
â”‚     â”œâ”€ __init__.py
â”‚     â””â”€ recommender.py
â””â”€ scripts/
   â””â”€ demo.py
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1) ì„¤ì¹˜

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\\Scripts\\activate
pip install -r requirements.txt
```

### 2) ë°ì´í„° ì¤€ë¹„

`insurance_core.csv`ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë˜ëŠ” ì„ì˜ ê²½ë¡œì— ë‘¡ë‹ˆë‹¤. **í•„ìˆ˜ ì»¬ëŸ¼**ì€ ì•„ë˜ `data/README.md` ì°¸ê³ .

### 3) ë°ëª¨ ì‹¤í–‰

```bash
python scripts/demo.py --csv ./insurance_core.csv \
  --gender ë‚¨ì \
  --premium 50000 \
  --coverage 10000000 \
  --age 25 \
  --job ì‚¬ë¬´ì§ \
  --k 10 \
  --sort_by distance
```

ì¶œë ¥ì€ ì¶”ì²œ ìƒìœ„ Kê°œ ìƒí’ˆ í…Œì´ë¸”ì…ë‹ˆë‹¤.

### 4) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì‚¬ìš©

```python
from life_insurance_recommender import Recommender
rec = Recommender().fit_csv("./insurance_core.csv")
result = rec.recommend_top_k(
    gender_input="ë‚¨ì",
    premium=50000,
    coverage=10_000_000,
    age=25,
    job_text="ì‚¬ë¬´ì§",
    k=10,
    sort_by="distance",
)
print(result)
```

---




class Recommender:
    """KNN ìœ ì‚¬ë„ ê¸°ë°˜ ì¢…ì‹ ë³´í—˜ ì¶”ì²œê¸°."""

    def __init__(self):
        self.df: Optional[pd.DataFrame] = None
        self.enc: Optional[_Encoders] = None
        # ì„±ë³„ í’€ ë¶„ë¦¬ìš©
        self.df_f: Optional[pd.DataFrame] = None
        self.df_m: Optional[pd.DataFrame] = None
        self.scaler_f: Optional[StandardScaler] = None
        self.scaler_m: Optional[StandardScaler] = None
        self.X_f_scaled: Optional[np.ndarray] = None
        self.X_m_scaled: Optional[np.ndarray] = None
        self.job2risk_lookup: Optional[dict] = None

    # ---------- Load / Fit ----------
    def fit_csv(self, csv_path: str) -> "Recommender":
        df = pd.read_csv(csv_path)
        return self.fit_df(df)

    def fit_df(self, df: pd.DataFrame) -> "Recommender":
        self.df = df.copy()
        required_cols = [
            "ìƒí’ˆëª…",
            "ì„±ë³„",
            "ë‚¨ì(ë³´í—˜ë£Œ)",
            "ì—¬ì(ë³´í—˜ë£Œ)",
            "ì§€ê¸‰ê¸ˆì•¡",
            "ê°€ì…ê¸ˆì•¡",
            "ë‚˜ì´",
            "ì§ì—…",
            "ì§ì—… ìœ„í—˜ë„",
        ]
        missing = [c for c in required_cols if c not in self.df.columns]
        if missing:
            raise ValueError(f"CSVì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")

        # Encoders
        job = LabelEncoder()
        jobrisk = LabelEncoder()
        product = LabelEncoder()
        gender = LabelEncoder()

        # Fit encoders on original text
        self.df["ì§ì—…"] = job.fit_transform(self.df["ì§ì—…"].astype(str))
        self.df["ì§ì—… ìœ„í—˜ë„"] = jobrisk.fit_transform(self.df["ì§ì—… ìœ„í—˜ë„"].astype(str))
        self.df["ìƒí’ˆëª…"] = product.fit_transform(self.df["ìƒí’ˆëª…"].astype(str))
        self.df["ì„±ë³„"] = gender.fit_transform(self.df["ì„±ë³„"].astype(str))

        self.enc = _Encoders(job=job, jobrisk=jobrisk, product=product, gender=gender)

        # Optional original columns
        if "ì§ì—…(ì›ë¬¸)" not in self.df.columns:
            try:
                self.df["ì§ì—…(ì›ë¬¸)"] = gender.inverse_transform(self.df["ì„±ë³„"]) * 0  # dummy to create col
                self.df.drop(columns=["ì§ì—…(ì›ë¬¸)"], inplace=True)
            except Exception:
                pass
        # Build jobâ†’risk lookup if possible
        self.job2risk_lookup = self._build_job_to_risk_lookup(self.df)

        # Split by gender after encoding: female==0, male==1 (LabelEncoder ê¸°ì¤€)
        self.df_f = self.df[self.df["ì„±ë³„"] == 0].copy()
        self.df_m = self.df[self.df["ì„±ë³„"] == 1].copy()

        # Scale features per gender pool
        self._fit_gender_pool()
        return self

    def _build_job_to_risk_lookup(self, df: pd.DataFrame,
                                  job_col: str = "ì§ì—…(ì›ë¬¸)",
                                  risk_col: str = "ì§ì—… ìœ„í—˜ë„(ì›ë¬¸)") -> Optional[dict]:
        if job_col in df.columns and risk_col in df.columns:
            try:
                return (
                    df.groupby(job_col)[risk_col]
                      .agg(lambda s: s.mode().iloc[0])
                      .to_dict()
                )
            except Exception:
                return None
        return None

    def _fit_gender_pool(self):
        # Female pool
        X_f = self.df_f[["ì—¬ì(ë³´í—˜ë£Œ)", "ì§€ê¸‰ê¸ˆì•¡", "ë‚˜ì´", "ì§ì—…", "ì§ì—… ìœ„í—˜ë„"]].astype(float).values
        self.scaler_f = StandardScaler().fit(X_f)
        self.X_f_scaled = self.scaler_f.transform(X_f)

        # Male pool
        X_m = self.df_m[["ë‚¨ì(ë³´í—˜ë£Œ)", "ì§€ê¸‰ê¸ˆì•¡", "ë‚˜ì´", "ì§ì—…", "ì§ì—… ìœ„í—˜ë„"]].astype(float).values
        self.scaler_m = StandardScaler().fit(X_m)
        self.X_m_scaled = self.scaler_m.transform(X_m)

    # ---------- Inference helpers ----------
    def _coerce_gender(self, g) -> int:
        if isinstance(g, str):
            g = g.strip()
            if g in ("ë‚¨", "ë‚¨ì", "M", "male", "Male"): return 1
            if g in ("ì—¬", "ì—¬ì", "F", "female", "Female"): return 0
            raise ValueError(f"ì„±ë³„ í•´ì„ ë¶ˆê°€: {g}")
        return int(g)

    def _to_job_code(self, job_text: str) -> int:
        assert self.enc is not None
        labels = list(self.enc.job.classes_)
        if job_text in labels:
            return int(self.enc.job.transform([job_text])[0])
        cand = get_close_matches(job_text, labels, n=1, cutoff=0.6)
        if not cand:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì§ì—…: {job_text}")
        return int(self.enc.job.transform([cand[0]])[0])

    def _infer_risk_from_job(self, job_text: str) -> Optional[int]:
        assert self.enc is not None and self.df is not None
        if self.job2risk_lookup and job_text in self.job2risk_lookup:
            risk_text = self.job2risk_lookup[job_text]
            return int(self.enc.jobrisk.transform([risk_text])[0])
        try:
            j_code = self._to_job_code(job_text)
        except Exception:
            return None
        sub = self.df[self.df["ì§ì—…"] == j_code]
        if sub.empty:
            return None
        mode_val = sub["ì§ì—… ìœ„í—˜ë„"].mode()
        return int(mode_val.iloc[0]) if not mode_val.empty else None

    def _restore_product_names(self, series_like: pd.Series) -> pd.Series:
        assert self.enc is not None
        try:
            if series_like.dtype == object:
                return series_like
            return pd.Series(self.enc.product.inverse_transform(series_like.astype(int)), index=series_like.index)
        except Exception:
            return series_like

    # ---------- Recommend ----------
    def recommend_top_k(
        self,
        gender_input: str | int,
        premium: float,
        coverage: float,
        age: int,
        job_text: str,
        k: int = 5,
        sort_by: SortBy = "distance",
    ) -> pd.DataFrame:
        if self.df is None:
            raise RuntimeError("fit_csv/fit_df ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        g = self._coerce_gender(gender_input)
        j_code = self._to_job_code(job_text)
        r_code = self._infer_risk_from_job(job_text)
        if r_code is None:
            r_code = int(self.df["ì§ì—… ìœ„í—˜ë„"].mode().iloc[0])

        base_vec = np.array([[float(premium), float(coverage), float(age), float(j_code), float(r_code)]], dtype=float)

        if g == 0:
            premium_col = "ì—¬ì(ë³´í—˜ë£Œ)"
            pool_df = self.df_f
            q_scaled = self.scaler_f.transform(base_vec)
            X_pool_scaled = self.X_f_scaled
        else:
            premium_col = "ë‚¨ì(ë³´í—˜ë£Œ)"
            pool_df = self.df_m
            q_scaled = self.scaler_m.transform(base_vec)
            X_pool_scaled = self.X_m_scaled

        # ì˜ˆì‚° ì´í•˜ í•„í„°
        mask = pool_df[premium_col] <= float(premium)
        idxs = np.where(mask.values)[0]
        if len(idxs) == 0:
            cols = ["ìƒí’ˆëª…", premium_col, "ì§€ê¸‰ê¸ˆì•¡", "ë‚˜ì´"]
            if "ì§ì—…(ì›ë¬¸)" in pool_df.columns:
                cols += ["ì§ì—…(ì›ë¬¸)", "ì§ì—… ìœ„í—˜ë„(ì›ë¬¸)"]
            return pd.DataFrame(columns=cols)

        # ê±°ë¦¬ ê³„ì‚°
        diffs = X_pool_scaled[idxs] - q_scaled
        dists = np.linalg.norm(diffs, axis=1)

        rec_rows = pool_df.iloc[idxs].copy()
        rec_rows["ìƒí’ˆëª…"] = self._restore_product_names(rec_rows["ìƒí’ˆëª…"])
        rec_rows["_distance"] = dists

        if sort_by == "premium":
            rec_rows["_sortkey"] = (rec_rows[premium_col] - premium).abs()
        elif sort_by == "coverage":
            rec_rows["_sortkey"] = (rec_rows["ì§€ê¸‰ê¸ˆì•¡"] - coverage).abs()
        else:
            rec_rows["_sortkey"] = rec_rows["_distance"]

        rec_rows = rec_rows.sort_values(by="_sortkey", ascending=True).head(k)

        show_cols = ["ìƒí’ˆëª…", premium_col, "ì§€ê¸‰ê¸ˆì•¡", "ë‚˜ì´"]
        if "ì§ì—…(ì›ë¬¸)" in pool_df.columns:
            show_cols += ["ì§ì—…(ì›ë¬¸)", "ì§ì—… ìœ„í—˜ë„(ì›ë¬¸)"]
        return rec_rows[show_cols].reset_index(drop=True)
```

## ğŸ§ª `scripts/demo.py`

```python
import argparse
import pandas as pd
from life_insurance_recommender import Recommender

parser = argparse.ArgumentParser()
parser.add_argument("--csv", required=True)
parser.add_argument("--gender", default="ë‚¨ì")
parser.add_argument("--premium", type=float, default=50000)
parser.add_argument("--coverage", type=float, default=10_000_000)
parser.add_argument("--age", type=int, default=25)
parser.add_argument("--job", default="ì‚¬ë¬´ì§")
parser.add_argument("--k", type=int, default=10)
parser.add_argument("--sort_by", choices=["distance", "premium", "coverage"], default="distance")
args = parser.parse_args()

rec = Recommender().fit_csv(args.csv)
res = rec.recommend_top_k(
    gender_input=args.gender,
    premium=args.premium,
    coverage=args.coverage,
    age=args.age,
    job_text=args.job,
    k=args.k,
    sort_by=args.sort_by,
)

# ê¹”ë”íˆ ì¶œë ¥
pd.set_option("display.max_columns", None)
print(res)
```

---

## ğŸ“Œ ì»¤ë°‹ ë©”ì‹œì§€ ì˜ˆì‹œ

* `feat: add KNN-based life-insurance recommender with per-gender scaling`
* `docs: write README and data schema`
* `chore: add requirements and gitignore`

---

í•„ìš”í•˜ë©´ **íŒ¨í‚¤ì§•(PyPI ë°°í¬ìš©)** ì„¤ì •(`pyproject.toml`)ê¹Œì§€ ë°”ë¡œ ë§Œë“¤ì–´ ì¤„ê²Œ. ë˜í•œ Spring Bootì—ì„œ ì´ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ í˜¸ì¶œ ì¤‘ì´ë©´, `scripts/demo.py`ë¥¼ ì°¸ê³ í•´ì„œ **ì…ë ¥/ì¶œë ¥ í¬ë§·(JSON ë¼ì¸)**ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ë²„ì „ë„ ì¶”ê°€í•´ì¤„ ìˆ˜ ìˆì–´!

